{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x1b6e5d76400>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://Done:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>ShortNSimple</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# initialize spark session\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .appName(\"ShortNSimple\") \\\n",
    "            .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['5.1,3.5,1.4,0.2,Iris-setosa',\n '4.9,3,1.4,0.2,Iris-setosa',\n '4.7,3.2,1.3,0.2,Iris-setosa',\n '4.6,3.1,1.5,0.2,Iris-setosa',\n '5,3.6,1.4,0.2,Iris-setosa',\n '5.4,3.9,1.7,0.4,Iris-setosa',\n '4.6,3.4,1.4,0.3,Iris-setosa',\n '5,3.4,1.5,0.2,Iris-setosa',\n '4.4,2.9,1.4,0.2,Iris-setosa',\n '4.9,3.1,1.5,0.1,Iris-setosa']"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "data = spark.sparkContext.textFile(\"C:\\\\iris.txt\")\n",
    "data.collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.rdd.RDD"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(data.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "150"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "len(data.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "str"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "type(data.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[5.1, 3.5, 1.4, 0.2]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "row = [5.1, 3.5, 1.4, 0.2, 'Iris-setosa']\n",
    "[float(val) for val in row[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iris-setosa\n"
    }
   ],
   "source": [
    "print(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Iris-setosa']"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "[row[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[5.1, 3.5, 1.4, 0.2, 'Iris-setosa']"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "[float(val) for val in row[:-1]] + [row[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'], [4.9, 3.0, 1.4, 0.2, 'Iris-setosa']]"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "data_splitted = data.map(lambda row: row.split(','))\n",
    "data_splitted = data_splitted.map(lambda row: [float(val) for val in row[:-1]] + [row[-1]])\n",
    "data_splitted.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "list"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "type(data_splitted.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"sepal_length\", T.FloatType(), True),\n",
    "    T.StructField(\"sepal_width\", T.FloatType(), True),\n",
    "    T.StructField(\"petal_length\", T.FloatType(), True),\n",
    "    T.StructField(\"petal_width\", T.FloatType(), True),\n",
    "    T.StructField(\"class_label\", T.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|class_label|\n+------------+-----------+------------+-----------+-----------+\n|5.1         |3.5        |1.4         |0.2        |Iris-setosa|\n|4.9         |3.0        |1.4         |0.2        |Iris-setosa|\n|4.7         |3.2        |1.3         |0.2        |Iris-setosa|\n|4.6         |3.1        |1.5         |0.2        |Iris-setosa|\n|5.0         |3.6        |1.4         |0.2        |Iris-setosa|\n|5.4         |3.9        |1.7         |0.4        |Iris-setosa|\n|4.6         |3.4        |1.4         |0.3        |Iris-setosa|\n|5.0         |3.4        |1.5         |0.2        |Iris-setosa|\n|4.4         |2.9        |1.4         |0.2        |Iris-setosa|\n|4.9         |3.1        |1.5         |0.1        |Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\nonly showing top 10 rows\n\n"
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(data_splitted, schema=schema)\n",
    "spark_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- sepal_length: float (nullable = true)\n |-- sepal_width: float (nullable = true)\n |-- petal_length: float (nullable = true)\n |-- petal_width: float (nullable = true)\n |-- class_label: string (nullable = true)\n\n"
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}